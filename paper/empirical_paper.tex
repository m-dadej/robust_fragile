\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{array} 
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{authblk}
\hypersetup{
	colorlinks,
	backref,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{matrix,shapes.geometric}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=2cm]{geometry}
\linespread{1.4}
\setlength{\bibsep}{0pt plus 0.3ex}

\bibliographystyle{apalike}
\title{Systemic Risk and Financial Connectedness: Empirical Evidence}
\author{Mateusz Dadej}
\date{\today}
\begin{document}

\maketitle

\section{Introduction}\label{section:introduction}

A fundamental characteristic that distinguishes systemic events from idiosyncratic ones is the relationship between the system's participants. A common sequence of a systemic contagion is when a supposedly firm specific event becomes transmitted into the cross-sectional dimension. Clearly, the way particular entities are interacting within the system is a key characteristic in order to understand the dynamics and severity of systemic events. This is what separates the common approach to systemic risk, where the stability of the system is but a sum of idiosyncratic risks, from the one that emphasizes the role of system structure. These contrasting distinctions are best captured by the concepts of \textit{too-big-to-fail} and \textit{too-interconnected-to-fail}. Where the former, emphasizes the sheer size of the entity and its potential impact on the system in case of default. On the other hand, the latter term describes the way the system depends on that particular institution, due to its central role within the system. It has been acknowledged, that the macroprudential policy was too focused on the sheer size of institutions, but insufficiently on their systemic contribution (see e.g. \cite{bernanke09} or \cite{rajan09}). That being said, it is crucial to view the system through the lenses of both of these approaches, for they are complimentary when assessing the stability of the financial system.

This approach to systemic risk, gave rise to the concept of \textit{robust yet fragile} property of the financial system. In the context of financial markets, the term was first coined\footnote{Before that, the term was commonly used in complexity science (see e.g. \cite{doyle05} and \cite{carlson02})} by the economist at the Bank of England, Andrew Haldane (\cite{haldane13}). He posits, that due to its interconnectedness, the financial system exhibits a tipping point property. The connections among financial institutions serve as shock absorbers, as long as the extent of the shock is limited. The common links allow for a shock to be spread throughout the network, at the same time suppressing the damage of the initial shock. However, once the extent of the shock exceeds a certain point, the properties of the contagion change markedly. The network of the institutions no longer works as a shock absorber, but as a shock amplifier of the initial disturbance. The damages are transmitted further on, disturbing the banks in a chain reaction. With the final contagion substantially exceeding the degree of the initial shock. The contagion is transmitted akin to the spread of the disease. 

A relatively new strain of literature, that incorporates the way institutions are forming financial networks, has emerged as a response to the increasing connections among market participants. The literature provides several theoretical models describing the aforementioned property\footnote{In fact, the \textit{robust yet fragile} property of the financial system was described before it was called as such (see e.g \cite{gai10}, first published in 2008, or \cite{gallegati08}).}. One of the extensions of the property is described in \cite{acemoglu13}. They provide a simple, yet profound model in which a more densely connected financial network improves the stability of the system when faced by a shock, relatively smaller in magnitude. On the other hand, similarly to the \textit{robust yet fragile} property, beyond some degree of the shock, more dense connections of the system are undermining the stability thereof. Thus, their conjecture highlights, that the network density may have a substantially different effect depending on which regime the markets currently are. 

Considering the above theoretical literature, this work aims at providing empirical evidence of the regime-dependent effect of network density on the stability of the financial system. The paper mostly follows the description of the \textit{robust yet fragile} property as in \cite{acemoglu13}. However, the evidence is easily applicable to the other models (see \cite{glasserman16} for an extensive literature review). To the best of knowledge, there has not been a study that provides empirical evidence of this phenomenon.

More precisely, the research design is a two-step process. First, to collect a time series of stock prices of the systematically important banks in both US and the Europe. Based on the data, the network between the banks and its density is estimated on a rolling window basis. In order to achieve robust results, the modeling approach is based on several methods, which are well established in the literature of network econometrics. This procedure results in a time series of financial connectedness for the particular financial market. In the second step, a Markov switching ARCH model is estimated, where the connectedness is the exogenous, regime-dependent variable. It is assumed, that a volatility of a particular banking index reflects the stability thereof. Additionally, the research provides a series of robustness checks by including the financial statement data of the banks in the modeling framework. The data is sourced from the Orbis database spanning from the 2016.

The model endogenously finds two distinct regimes of the analyzed relationship. The results indeed provide evidence confirming the set of theoretical models. The effect of the network density on the stability of the financial system varies depending on the regimes. However, the effect is very asymmetrical. During the stable market regime, the network density has almost no effect on the stability of the financial system. At the same time, more dense financial networks are undermining the stability of the system during the unstable market regime\footnote{\cite{acemoglu13} describe these regimes as "small shock" and "large shock" respectively.}. It is, thus, evident that the increased bank interconnectedness is in total a damaging property of the financial markets. 

The remainder of the paper is structured as follows. The next section provides a brief literature review and its link to this paper. Section \ref{section:Data} describes the data and provides preliminary statistics. The methods employed to estimate the connectedness of the financial sectors are described in section \ref{section:fin_network}. The estimated networks are analyzed in section \ref{section:network_results}. The modeling of regime-dependent effect of connectedness is described in section \ref{section:arch_model} and its main results are presented in section \ref{section:main_results}. The robustness check and its results are described in sections \ref{section:robustness}. Section \ref{section:conclusion} concludes.

\section{Literature}\label{section:literature}

As the research aims at connecting the theoretical models of financial networks with the empirical evidence, the relevant literature is divided into theoretical and empirical parts.

One of the earliest seminal models describing contagion through the lens of financial networks was \cite{allen00}. Where they arrive to the very intuitive conclusion, that a complete network\footnote{In graph theory, a complete graph has connections among all of its nodes.} between the banks, is more robust to the contagion than an incomplete one. The mechanism is that a more diversified network of banks allows the liquidity shock to spread among the network. A similar conclusion can be drawn from the work of \cite{freixas00}, where they also emphasize the role of the central bank in coordinating the banking system during contagion. An important advancement in analyzing financial networks was introduced in \cite{eisenberg01}. They provide a method to obtain a clearing vector among the banks that clears their obligation. Additionally, they prove the uniqueness of the vector. The method is extensively used for modeling the contagion in the financial networks and has been extended, e.g. for liquidity consideration (\cite{cifuentes05}) or for liquidation costs (\cite{rogers13}). 

Since the first work that models banking systems as a financial network, there was an increased effort into describing alternative ways of contagion propagation in this framework. One of the very first ones was described in \cite{cifuentes05}, where the banks are interconnected through common market asset holdings. They show, that when the market's demand for illiquid assets is not perfectly elastic, selling them on the market by the banks may decrease prices substantially. At the same time, due to mark-to-market accounting, other banks with the same holdings may be under pressure to sell their assets, further depressing and generating fire sales. This contagion may begin even from lesser shocks. \citet{elliot14} emphasizes the role of bankruptcy cost in amplifying the cascading effect of the contagion. Their model also distinguishes integration from network connectedness, defining it as a degree of dependence on the network. They show, that although integration can increase the likelihood of a cascade once an initial failure happens, it might also decrease the chance of that first failure. \cite{caballero13} shows, that once the contagion begins, the banks are facing an increasingly complex environment as they need to monitor the bigger part of the network in order to control their own default risk. This uncertainty induced counterparty risk causes precautionary behavior among banks, further exacerbating the fire sale. As much as there are plentiful hypothetical channels of financial contagion from the literature, this work keeps an agnostic stance on the type of connections between the financial institutions\footnote{That being said, one of the financial network estimation method employed and described in the section \ref{subsection:granger} controls for common exposures, thus excluding this channel of contagion.}. This is because connections are inferenced from the stock prices, which are known to contain very broad variety of information of the issuer.

A considerably more relevant strain of literature to herein research considers the nonlinear effect of connectedness on contagion dynamics. Based on the previously studied concept of percolation on random graphs from complexity science (\cite{callaway00} or \cite{newman001}), \cite{gai10} show that the financial system exhibits a similar form of phase transition. Specifically, due to the dense structure of the financial networks, the likelihood of contagion is particularly low. However, the same property makes the contagion very severe once it happens. Based on the same model, \cite{may10} apply mean-field approximation, to identify the contribution of various parameters in the model to the likelihood and severity of the contagion. An already mentioned research of \cite{acemoglu13}, goes beyond the model of \cite{gai10}. They suggest, that the degree of connectedness of the financial system has a regime-dependent effect on stability, at the same time proving the narrative of Andrew Haldane (\cite{haldane13}). The literature on regime-dependent effect of connectedness on stability, and more precisely the robust-yet-fragile concept is vast. However, insofar it was limited mostly to the theoretical works. The contribution of this research is exactly to provide empirical evidence of these studies as well as the intuition of policymakers.  

Since the work is mostly empirical in nature, it is also imperative to position it in the literature of network econometrics. Although scarce in data, there have been several works statistically describing the actual transaction level data\footnote{The data is often proprietary to the public entities regulating the financial markets.} and thus, the network among the banks.  Using Bundesbank data on bilateral interbank exposures among 2000 banks from 1999 to 2012, \cite{craig14} provides evidence for tiering on the interbank market. The banks are forming a very hierarchical network, where lower-tiered banks interact with each other, mostly through intermediating, bigger banks \footnote{A similar behavior is also present in other economic networks e.g. international trade (\cite{antras11})}. The tiering behavior is modeled and commonly referred to in the literature as a \textit{core-periphery} structure. Based on the Italian interbank market data from January 1999 to December 2010, \cite{fricke2015} confirms previous contribution, at the same time showing, that the core of the financial network is highly persistent in time. That is, the banks forming the core don't change the position in the structure. \cite{langfield14} extend the previous research with the data across other class of assets held among the banks (such as derivatives, marketable securities, repo, unsecured lending and secured lending). They emphasize particular heterogeneity of the financial network, by distinguishing between interbank funding and interbank exposures. The structure is significantly different among these types, thus the dynamics of contagion varies depending on the source of risk (liquidity vs. credit risk). Clearly, the contribution of this part of the literature is mostly in describing the stylized facts present in the current financial networks. This is valuable for studies that estimate the connections from limited amount of data, as the estimated network may be validated with respect to the desirable characteristics of the network. This is exactly the exercise being done (in the section \ref{section:fin_network}) in this research in order to check the robustness of network estimation methods. 

As much as the network data is available (although to the very limited extent), the econometricians aimed at estimating the financial networks from broadly available sources, mostly from equity price time series. \cite{billio12} describe a pair of econometric methods, that are employed as part of this work. They use monthly stock prices of insurers, hedge funds and banks to estimate their interconnectedness. In the first approach they suggest a model based on principal component analysis (Hereafter referred to as PCA, \cite{murihead09}). When used on the covariance matrix of stock returns, the PCA will provide a set of factors eigenvalues best describing the variation of the system. A higher share of the variance, explained by top eigenvalues, indicates elevated connectedness in the system. A second model provides more detailed information by estimating a whole directed network of the financial institutions. The method is based on the "Granger causality" (\cite{granger69}) among the pair of allegedly connected entities. The financial network is constructed by performing the granger test on each of pairs of the stock returns with adjacency matrix entries being one or zero depending on the outcome of the test. The resulting approach allows higher flexibility in analyzing the topology of the network and deciding the measures of connectedness (the authors use a range of different network measures). These methods are employed in the research design and more closely described later on. 

An alternative methodology to estimate financial networks from stock price data was developed by \cite{deibold14}. In their work, the financial network\footnote{Or in the paper's terminology - a connectedness table.} is estimated as a matrix of parameters from the Vector Autoregression model (\cite{sims80}). Precisely, the adjacency matrix of the network is the $\Theta$ from the VAR matrix notation: $\boldsymbol{y}_t = \theta_o + \boldsymbol{\Theta} \boldsymbol{y}_{t-1} + \epsilon_t$. In a similar vein to \cite{billio12}, the authors use their method to estimate the network and appropriate connectedness measures among the financial institutions from the USA\footnote{The same approach was applied also to other data. For example, international trade (\cite{deibold23}) commodities (\cite{diebold17} and \cite{gong22}), cryptocurrencies (\cite{ji19}), particular pair of countries (\cite{dadej23})  and among the whole asset classes (\cite{bouri21}).}. As these methods may seem to be substitutable at first, the authors themselves point out the differences between their approach and that of \cite{billio12}. Considering the VAR methodology, it is evident that the resulting network of connections is weighted, unlike the Granger-based approach. This provides another dimension to analyze the strength of the links between the institutions. Moreover, at least in the standard formulation, the Granger-based approach is only pairwise. That is, it does not control the spurious relationship, stemming from the confounding third (or more, in that matter) entity. However, the Granger-based method is flexible enough to extend the main regression used to test using the Granger causality by more control variables. There are, of course, some disadvantages to rely on the VAR approach. It requires identifying assumptions related to the variance decomposition. Also, what is more relevant to the research herein is the higher computational burden coming from the VAR approach. Given that the research design does not require information on link weights and is computationally expensive, the approach of \cite{billio12} was considered to be more appropriate.

There are a number of alternative methods used for estimating networks in general, but more often used in other fields of study. A common approach from systems biology is Gaussian graphical models (e.g. applied in \cite{friedman04}). They allow for maximum likelihood estimation with penalization, producing a robust network estimation. Some of the applications in finance were estimating international finance flows (\cite{giudici16}) or systemic risk in the banking sector (\cite{cerchiello16}). \cite{barigozzi19} employs networks to estimate networks with VAR, but they extend the methodology with LASSO estimation (\cite{breiman95}), allowing for sparsity of the network and improved forecasting.

Another strain of literature, suggesting the methods to estimate financial networks, comes from a different data source. Banks do not provide counterparty information in their financial statements, but they do show their aggregated values for both lending and borrowing on the interbank market. This is a source of hard data that provides the marginal values for the adjacency matrix of the network, i.e. the columns and rows sums. Several authors provided methods of filling the adjacency matrix at the same time satisfying some stylized facts regarding financial networks. The stylized facts are provided by research based on the actual data (surveyed before in herein section) or commonly accepted economic rationale, e.g. no self-lending restrictions. One of the most common approaches is to estimate the network as evenly as possible. This method, known as \textit{maximum entropy} (\cite{upper11}), assumes that banks are trying to diversify their holdings as much as possible. The supposition, that banks are diversifying as much as possible, may seem appealing at first. However, due to the monitoring costs and informal relationships (\cite{brauning16}) among banks (\cite{cocco09}), it is not realistic. Most likely overestimating density of the actual financial network. Having that in mind, \cite{anand15} suggest a \textit{minimum density} method which minimizes the total number of linkages necessary for allocating interbank positions. An appealing characteristic of the method is that it is overestimating the degree of contagion (according to the author's comparison). This is contrary to the benchmark methods, which more often underestimate it. A method suggested by \cite{baral12}, draws link weights based on the copula distribution fitted to the aggregated interbank data. \cite{cimini15} uses a fitness model based on the likelihood  of directed connections with additional knowledge of the node's parameters. \citet{drehmann13} takes into account a commonly recognized stylized fact regarding the interbank market, that the network exhibits a \textit{core-periphery} structure. Their method provides a reconstructed matrix with \textit{core-periphery} characteristics. \cite{halaj13} suggest an iterative method where the network links are drawn randomly until the network is reconstructed. The above methods are compared together in a horse race described in \cite{anand18}.

A literature considering connections between financial institutions in the context of systemic risk and contagion is vast. Considering the increased importance of connectedness for assessing the systemic risk, \cite{hautsch14} improve on the works of \cite{adrian16} to propose the realized systemic risk beta. The measure specify the contribution of particular financial institution to the systemic risk, given its position in the network. A similar metric is suggested by \cite{dungey12}. They rank financial institutions in order of their systemic importance, considering their correlation-based connectedness. \cite{savona14} estimate dynamic conditional correlation model, in order to study the contagion among the hedge funds. The author shows, that correlations are key factor for predicting depressed hedge fund returns. A broader perspective is shown in the work of \cite{minoiu15}. According to their research, an elevated country connectedness, and at the same time, decrease in those of its neighbors, is able to predict the banking crisis.

As mentioned there is not quite a study providing an empirical evidence for the \textit{robust-yet-fragile} phenomena of financial networks. There are, however, works that are the most closely related to this study in terms of analyzed phenomena. \cite{everett21} analyze global connectedness across firms from different industries. Based also on their equity returns, they find that more globally connected firms are less likely to be in distress. A primary difference is that, unlike herein study, their work does not aim to estimate the regime-dependent effect of connectedness. A regime switching model of contagion across the sovereign debt markets is developed by \cite{saida18}. His Markov-switching copula model distinguishes between a contagion and stable regime and analyzes the transmission between countries. Yet, his study is not investigating the varying degree of connectedness among the markets on contagion dynamics.
There are several studies estimating the regime-switching models of contagions but completely agnostic to the connectedness, i.e. \cite{lopes12}, \cite{savona15}, \cite{guo11} or \cite{chan19}.


\section{Data}\label{section:Data}

The main set of results is based on the equity stock prices and index data. The stock data is adjusted for corporate actions such as splits and dividends. The analysis focuses on the data of financial institutions from the two biggest financial sectors. Namely, that of the United States and Europe. An exact list of the institutions follows the stress test exercises from both of the banking sectors analyzed (\cite{eba2021} and \cite{fed21}). The number of institutions is 31 and 42 for the USA and Europe respectively. The full list is presented in the table \ref{table:bank_list} in the appendix \ref{appendix:data}. Not every company was listed from the beginning of the analyzed period. The list of the first available price data (thus including in the analysis) is presented in table \ref{table:ipo} in the appendix \ref{appendix:data}. Additionally, the relevant banking indices are used as a proxy of financial stability (KBW Nasdaq Bank Index and EURO STOXX® Banks) and broad market indices for control (S\&P500 and STOXX® Europe 600). Since the main results are based on only equity price data, the frequency of time series is daily. This allows to capture a relatively sharp and brief market contagions. The source of the equity prices and indices data is Yahoo Finance.  A robustness check incorporates financial statements of the institutions into the analysis. The financial variables are obtained from the Orbis database for each quarter between 2016Q3 and FY2023\footnote{However, due to missing reports for some institutions, the actual data used is smaller}. 

\subsection{Summary statistics}\label{subsection:data_descrptive}

Table \ref{table:descriptive} reports descriptive statistics of the stock price data for both of the markets. On average, the stock prices have a (slight) upward trend with the average return being positive and similar for both of the markets. However, once the sample is split pre- and post-Great Financial Crisis (hereafter referred to as GFC), there are substantial differences. The average returns are higher post-GFC for the USA than before. Au contraire, the European returns were higher pre-GFC. It clearly shows the banking dimension of the debt crisis that hit Europe in the second decade of the 21st century. It is also evident that the European market is more volatile. Every dispersion measure is higher for Europe than USA. This is as expected, considering the more severe banking crises in a lot of European member states (e.g. Greece, Italy and Ireland). Unlike in the USA, where there was no substantial banking contagion after the 2008 subprime crisis. 

% latex table generated in R 4.3.2 by xtable 1.8-4 package
% Sat Jul 20 20:45:35 2024
\begin{table}[h]
	\centering
	\begin{tabular}{r|r|r}
		market & EU & USA \\ 
		\hline \hline
		Average return (\%)& 0.0395 & 0.0412 \\ 
		Std. deviation (\%)& 3.83 & 2.49 \\ 
		max drawdown (\%)& -88.77 & -83.17 \\
		1\% percentile (\%)& -7.55 & -6.63 \\ 
		99\% percentile (\%)& 7.76 & 6.99 \\ 
		worst return (\%)& -93.33 & -59.03 \\ 
		max return (\%)& 1400 &   86.9 \\ 
		Average correlation & 0.398 & 0.617 \\
		Sample size & 5748 & 5844 \\ 
	\end{tabular}
	\caption{Descriptive statistics of the data. The statistics are averages over stock returns and markets. In case of maximum and minmium values, the minimum (for stocks) of the minimum (for each market) and vice versa for the maximum.}
	\label{table:descriptive}
\end{table}

The American market is on average more correlated than the European one. The reason is a more fragmented banking sector\footnote{Although, the concept of banking union is discussed.} in Europe, with different member states having separate banking laws, regulators, capital markets and, in general, a more heterogeneous real economy. That being said, the systemic risk of the banking sector is indeed a EU-wide concern (see e.g. \cite{song21}). 

\section{Financial network connectedness}\label{section:fin_network}

Because of lack of public data from the interbank market, or as a matter of fact, any bilateral contractual obligations between the banks, the academic literature developed a set of tools to estimate the financial networks from available sources. As shown in the literature, these methods are well established and commonly applied in order to estimate financial connections. This is despite some of their limitations. One may wonder how the stock prices reflect information that is not public? There is, however, evidence that the stock prices also discount some unknown information to the public, e.g. due to insider trading or inferred from other data. A classic example is \cite{newhard14}, describing, allegedly, the first ever event study performed on stock prices. Based on the outperformance of lithium producers, he inferred the fuel material used in the manufacturing of the newly-developed hydrogen bomb. An information which was non-public, to the extent that his paper was confiscated. The literature on insider trading and non-public information on the stock market is vast and extends beyond the scope of the herein paper (see e.g. \cite{hawk90}, \cite{huddart07} or \cite{klein20}). As well as assessment of the methods to estimate the financial network.

A schematic representation describing the problem faced by both \cite{billio12} and \cite{diebold17} of financial network estimation is shown in the Figure \ref{fig:connectedness_scheme}. Based on the multivariate time-series data matrix $X$, consisting of stock price returns, the authors suggest a method ($f$) of inferring an adjacency matrix ($\boldsymbol{A}$), describing the connections among financial institutions. As shown, the adjacency matrix has a number of columns and rows equal to the number of entities. Each of the elements in the adjacency matrix $\boldsymbol{A}$, describes the connections between the entities. That is, $a_{i,j} > 0 \Rightarrow i \rightarrow j \; \forall \;  i \neq j$. In economic applications, the diagonal values are usually zero, as there is no intuition behind a self connection of a financial institution. Each $a_{i,j}$ can take binary values in the case of an unweighted graph or any other real-valued number in the case of a weighted graph. A very useful property, linking linear algebra and graph theory, is that every graph has its own adjacency matrix (and vice versa). Thus, a variety of graph theory measures may be applied to the estimated network of connections. One of the most common measures describing financial connectedness is the average degree, which is the average number of edges each of the graph nodes has. The measure may provide a single value number describing the connectedness of the entirety of the financial system (at least so far as goes the number of included financial institutions). 

\begin{figure}
	\begin{tikzpicture}	
		% Matrix
		\begin{scope}[scale = 0.9, xshift=0.5]
			\matrix (m) [matrix of math nodes,left delimiter=(,right delimiter=),ampersand replacement=\&] {
				x_{11} \& x_{12} \& \dots \& x_{1n} \\
				x_{21} \& x_{22} \& \dots \& x_{2n} \\
				x_{31} \& x_{32} \& \dots \& x_{3n} \\
				\vdots \& \vdots \& \ddots \& \vdots \\
				x_{T1} \& x_{T2} \& \dots \& x_{Tn} \\
			};
			
			\draw [decorate,decoration={brace,amplitude=10pt}]
			(2.6,-1.8) -- (-2.6,-1.8) node [black,midway,xshift=0cm,yshift=-0.7cm] 
			{\footnotesize Time series matrix $\boldsymbol{X}$ of size $T \times n$.};
		\end{scope}
		
		\begin{scope}[scale= 0.6]
			\draw[->, line width = 0.7] (5,0) -- (8,0) node[midway, above] {\footnotesize $f: \mathbb{R}^{T\times n}\to \mathbb{R}^{n \times n}$};
		\end{scope}
		
		\begin{scope}[scale = 0.9, xshift = 8.5cm]
			\matrix (m) [matrix of math nodes,left delimiter=(,right delimiter=),ampersand replacement=\&] {
				a_{11} \& a_{12} \& \dots \& a_{1n} \\
				a_{21} \& a_{22} \& \dots \& a_{2n} \\
				\vdots \& \vdots \& \ddots \& \vdots \\
				a_{n1} \& a_{n2} \& \dots \& a_{nn} \\
			};
			
			\draw[decorate,decoration={brace,amplitude=10pt}]
			(2.6,-1.6) -- (-2.6,-1.6) node [black,midway,yshift=-0.9cm] 
			{\footnotesize Adjacency matrix $\boldsymbol{A} \times n$.};
		\end{scope}
		
		\draw[line width=1pt] (7.5,-2.9) -- (7.5,-3.4);
		\draw[line width=1pt] (7.35,-2.9) -- (7.35,-3.4);
		
		% Pentagram graph
		\begin{scope}[xshift=7.5cm, yshift = -5.5cm, scale=0.8]
			\node[draw, circle, inner sep=1pt] (a) at (90:1.8) {$x_p$};
			\node[draw, circle, inner sep=1pt] (b) at (162:2) {$x_1$};
			\node[draw, circle, inner sep=1pt] (c) at (234:2) {$x_2$};
			\node[draw, circle, inner sep=1pt] (d) at (306:2) {$x_3$};
			\node[draw, circle, inner sep=1pt] (e) at (18:2) {$x_4$};
			
			\draw[<->] (a) -- (c);
			\draw[<->] (c) -- (e);
			\draw[<->] (e) -- (b);
			\draw[<->] (b) -- (d);
			\draw[<->] (d) -- (a);
			
			\draw[<->] (a) -- (b);
			\draw[<->] (b) -- (c);
			\draw[<->] (c) -- (d);
			\draw[<->] (d) -- (e);
			\node[xshift=1.9, yshift=2.1, scale=1.1] at ($(e)!.5!(a)$) {$\ddots$};
			%\draw[dotted, <->] (e) -- (a);
			
			\draw [decorate,decoration={brace,amplitude=10pt}]
			(2,-2) -- (-2,-2) node [black,midway, yshift=-0.6cm] 
			{\footnotesize Graph representation of matrix $\boldsymbol{A}$.};
			
		\end{scope}
	\end{tikzpicture}
	\caption{Scheme describing the process of financial network estimation.}
	\label{fig:connectedness_scheme}
\end{figure}

In what follows in the section, the particular methods of estimating financial networks are described. Out of the three methods employed in the research design, the last two of them follow the work of \cite{billio12}. With the first one suggested by the author. 

\subsection{Ledoit-Wolf covariance}\label{subsection:ledoit_wolf}

This approach follows a commonly applied in finance (and in portfolio optimization in particular) shrinkage method suggested by \cite{ledoit03}.The idea behind shrinkage is to compute the convex linear combination of sample covariance $\hat{\Sigma} = \frac{1}{N}\boldsymbol{X}'\boldsymbol{X}$ (with elements $\hat{\sigma}_{i,j}$) of rates of returns matrix $\boldsymbol{X}$ and an identity matrix $\mathbb{I}$:

\begin{equation}
	\tilde{\Sigma} \coloneqq \rho_1 \mathbb{I} + \rho_2 \hat{\Sigma}
\end{equation}

The optimal linear combination above is the solution to the following quadratic program subject to linear constraint:

\begin{equation}
	\begin{aligned}
	\max_{\rho_1, \rho_2} \quad &  \mathbb{E}[|| \tilde{\Sigma} - \Sigma||^2] \\
	\textrm{s.t.} \quad & \tilde{\Sigma} = \rho_1 \mathbb{I} + \rho_2 \hat{\Sigma}
	\end{aligned}
\end{equation}

Where the $||\cdot||$ is the Frobenius norm defined\footnote{For the purpose of this exercise, this is a slightly modified version of the Frobenius norm.} as $||A|| = \sqrt{\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{N} a_{i,j}^2}$. With solution equal to:

\begin{equation}
	\tilde{\Sigma} = \frac{\beta^2}{\delta^2} \mu \mathbb{I} + \frac{\alpha^2}{\delta^2} \hat{\Sigma}
\end{equation}

The estimators of $\beta^2$, $\delta^2$, $\alpha^2$ and $\mu$ being:

\begin{equation}
	\begin{aligned}
	\hat{\mu}_T = \frac{1}{N} \sum_{i=1}^{N} \sigma^T_{i,i} \\
	\hat{\delta}^2_T = ||\hat{\Sigma}_T - \hat{\mu}_T \mathbb{I}_T ||^2 \\
	\hat{\beta}^2_T = \min \left\{ \frac{1}{T} \sum_{t=1}^T || x_t^T (x_t^T)' - \hat{\Sigma}_T||^2,\, \hat{\delta}^2_T \right\}
	\end{aligned}
\end{equation}

Once the shrinked covariance matrix is estimated, it is assumed to reflect the underlying connections among the financial institutions. The connectedness is thus measured as an average Ledoit-Wolf covariance among the entities:

\begin{equation}
	\gamma_{lw} = \frac{\sum_{i \neq j}^{N} \sum_{j \neq i}^N \tilde{\sigma}_{i,j}}{N^2 - N}
\end{equation}

Where $\tilde{\sigma}_{i,j}$ are, as before, elements of the matrix $\tilde{\Sigma}$.

The procedure tends to pull the most extreme parameters into more central values, thus systematically reducing estimation errors. The estimation error is especially substantial when the dimension of the analyzed data is high, with respect to the number of observations available. Another work by the original authors \cite{ledoit04} performs a Monte Carlo simulation study benchmarking alternative ways to estimate the covariance matrix and shows the superiority of their approach for large dimensional data. This is considerably relevant considering the research design of this work. As mentioned before, the connectedness measure will be calculated on a rolling window basis. Often as small as a single quarter (63 observations vs. 42 variables). 

\subsection{Principal component analysis}\label{subsection:pca}

A connectedness measure based on the principal component analysis (PCA) is the first method suggested by \cite{billio12}. The idea is to calculate the share of variance explained by the top $k$ component. In principle, the PCA is the eigendecomposition of a covariance matrix (with variance of covariates scaled to one). Namely, we wish to find an eigenvector $\mathbf{v}$ and eigenvalue $\lambda$ that satisfy the following equation:

\begin{equation}
	\hat{\Sigma} \mathbf{v} = \lambda \mathbf{v}
\end{equation}

The values of interest may be find solving a homogeneous system of
linear equations $|\hat{\Sigma} - \lambda \mathbb{I}| = 0$, with $|\cdot|$ being a determinant operator. An important property of the eigenvectors is their orthogonality. The covariance matrix is decomposed in a following way:

\begin{equation}
	\hat{\Sigma} = \mathbf{Q}\mathbf{\Lambda}\mathbf{Q}'
\end{equation}

Where $\mathbf{\Lambda} = \text{diag} \{\lambda_1, \lambda_2, \dots, \lambda_n \}$ and $\mathbf{Q}$ is an orthogonal matrix whose columns are unit eigenvectors. Thus, the eigendecomposition yields a set of uncorrelated components fully explaining (linearly) the underlying covariance matrix. The eigenvalues reflect the variance explained by the relative eigenvector.

In the context of the data used in this research, the biggest eigenvalue shows the amount of variance of the returns, explained by the most important factor. Thus, the relevant measure of the connectedness is:

\begin{equation}
	\gamma_{pca} = \frac{\max \{\mathbf{\lambda}\}}{\mathbf{\lambda}'\mathbf{1}}
\end{equation}

Where $\mathbf{1}$ is a vector of ones with an appropriate size. The measure may be interpreted as a share of the single most important component in explaining the total sum of the variances. It is clear, that the measure has some drawbacks when analyzing connectedness. The procedure does not yield connections among the institutions (other than covariance itself) but a single measure of connectedness. Notwithstanding this disadvantage, the measure is useful in the context of this research design, as the main objective of this stage is to obtain a single connectedness measure. 

\subsection{Granger based connectedness measure}\label{subsection:granger}

The approach, that yields not only a network of the connections but also its directionality is based on the concept of Granger causality (\cite{granger69}). The variable $x_t$ is said to "Granger-cause" a variable $y_t$ if it contains enough information at time $t-1$ to predict the respective variable in the next period $t$. Naturally, this statement is tested by running a regression with lagged variable:

\begin{equation}\label{equation:granger}
	y_t = \beta_0 + \beta_1 x_t + \underbrace{\sum_{i=1}^{p} \beta_{i+1} y_{t - p}}_{\text{lag controls}} + \epsilon_t
\end{equation}

Where $\beta$ are the estimated coefficients and $\epsilon_t$ the uncorrelated error term. The variable $x_t$ is said to Granger-cause $y_t$ if the respective coefficient, $\beta_1$ is significantly different from zero. In the context of financial markets, the above approach may appear to be implausible to a lot of financial economists. That is because of the relatively high degree of information efficiency, considering that we analyze the most liquid markets in the world. This efficiency implies that any publicly accessible information should yield no predictive ability, thus rendering the equation \ref{equation:granger} pointless. That being said, the test indeed finds the underlying connections \footnote{Even with a frequency higher than the applied confidence interval.}. This is due to several factors. The primary one, is that the statistical significance is not equal to the economic one. Any execution of a potential strategy following the equation \ref{equation:granger}, will stumble upon the transaction costs, including slippage and commissions, which will make the exercise unprofitable. Thus, the granger causality may just as well be seen as a return spillover between the institutions, as shown in \cite{battison12}.

The exact procedure employed in the research design is slightly modified\footnote{\cite{billio12} performs the Granger causality test by filtering the returns with GARCH(1,1) process and then using the time-varying variance to test the significance of the $\beta$ coefficient from the regression. This approach is, however, computationally more expensive. This technical dimension is more relevant to this study as the connectedness is measured on a rolling window basis. Unlike in the original study of \cite{billio12}.}. The procedure use excess returns of the institutions' stock prices over a relevant benchmark of market rates of return. Consequently, the returns of the institutions will have a purely idiosyncratic character. The regression has the following specification:

\begin{equation}\label{equation:granger_used}
	r_{i,t+1} = \beta_0 + \beta_1 r_{j,t} + \beta_2 r_{i, t} + \underbrace{\sum_{i=1}^{k} \beta_{i+2} x_{t}}_{\text{Sectoral controls}} + \epsilon_t
\end{equation}

Financial institutions are assumed to be connected when the $\beta_1$ coefficient is statistically different from 0. The sectoral controls consist of rates of returns of the consumer discretionary ETF, Real Estate ETF, crude oil WTI and treasure bills of 3-month and 10 year maturity. These variables control common shocks among institutions. Since the institutions may have common exposures (e.g. to real estate through mortgage portfolios), a shock to the real estate market could hit both of the institutions equally, showing potential Granger causality, despite no bilateral contractual obligations between them. By introducing some of the sectoral controls, the research design is free from this sort of relationship. It is, however, important to note, that these channels are also of concern in the theoretical literature studying contagion in financial networks. This channel is described e.g. by \cite{cifuentes05} and may play an actual role in the mechanism describing the \textit{robust-yet-fragile} phenomena. That being said, this is one of the three other methods for estimating financial connectedness in this study and the only one where controlling for the common shock is possible. Thus, other measures will be allowed to capture this channel. 

The above Granger analysis is ran on every pair of the institutions. The adjacency matrix of the financial network $\boldsymbol{A}$ has following entries:

\begin{equation}
	a_{i,j} = \begin{cases}
		1  & \text{if } \beta_1 \text{ is significant} \\
		0 & \text{otherwise}
	\end{cases} \; \forall \; i \neq j
\end{equation}

Thus, the resulting graph is unweighted, because the adjacency matrix is binary. However, this is only a matter of choice. The entries might as well be equal to the effect size $\beta_1$. This is, however, unnecessary, given the research design. Since the Granger causality is not granted, the network is also directed. Clearly, these properties of the approach are beneficial with respect to the rest employed. The method is also different in a way that it measures the lagged connection between entities. 

The connectedness measure is then calculated in a similar manner as for the Ledoit-Wolf approach:

\begin{equation}
\gamma_{g} = \frac{\sum_{i \neq j}^{N} \sum_{j \neq i}^N a_{i,j}}{N^2 - N}	
\end{equation}

\section{Network estimation results}\label{section:network_results}

\subsection{Static analysis}\label{subsection:static}

Although the ground truth of the true financial network is unknown, it is still informative to investigate the properties of the estimated networks. This way, we can evaluate if the estimation results are economically sensible. Figure \ref{fig:actual_network} shows two representations of the same graph, estimated with the Granger-based method. The data used for the estimation is from 2023, as the actual links among the financial institutions is concentrated on this horizon\footnote{The data on maturity structure on interbank market is scarce as well. A bit outdated but complete sample from the German interbank market from 2000 reports that around 40\% of the interbank debt has maturity of less than a year (\cite{upper04}). The inclusion of derivatives would most likely increase this share.}. It is clear from the visual presentation of the network, how dense the connection is\footnote{The definition of \textit{density} as well as other network statistics used in this section and henceforth is described in the appendix \ref{appendix:network_metrics}.}. As reported in table \ref{table:network_metrics}, the visualized graph is denser than for the USA market and different time periods. The European financial sector is less densely connected than the USA, in both of the periods from the example. This is to be expected (also from the descriptive statistics in the subsection \ref{subsection:data_descrptive}), considering that the banking sector is more fragmented due to separate jurisdictions. In absolute terms, every estimated network is somewhat denser \footnote{This is, however, arbitrary to some degree. The level of density might be as well manipulated by choosing levels of a different confidence level when checking the $\beta$ coefficient significance in the Granger test. Increasing its level from 95\% to e.g. 99\% would decrease the density. The level of significance is decided by convention rather than evidence from empirical literature based on transaction level data.}. One of the lowest estimates of the density comes from the work of \cite{anand15}. Based on the German interbank market, they report the density to be around 0.59\%. On the other hand, one of the highest reported values of density is 15\% from the Italian e-MID interbank market (\cite{fricke15}). The estimates clearly vary substantially, most likely depending on the types of instruments considered a connection among the institutions, as well as the sample of banks. Other than the purely arbitrary level of confidence in the Granger test, the reason of increased density of the estimated network is the subsample of only systematically important institutions. This, by definition, makes them more connected to the rest of the system, rather than the e.g. regional banks. Still, the density is within estimates from the empirical literature, ensuring that the estimated network is economically sensible (or the chosen confidence level).

\begin{figure}%
	\centering
	\subfloat[\centering Circle representation of graph]{{\includegraphics[width=7cm, height=7cm]{img/graph_eu_circl.png} }}
	\quad
	\subfloat[\centering 
	Representation of graph with random position]{{\includegraphics[width=7cm, height=7cm]{img/graph_eu.png} }}\\
	
	%	\subfloat[\centering Representation with random position]{{\includegraphics[width=7cm, height=7cm]{img/graph_us.png} }}
	%	\quad	
	%	\subfloat[\centering Circle representation of graph]{{\includegraphics[width=7cm, height=7cm]{img/graph_us_circl.png} }}
	
	\caption{Financial network visualization based on the European market data from 2023. Each point (node) represents a financial institution and the connections (edges) are links estimated with the Granger causality method. The arrows indicate the direction of particular link. Each node is labeled with the ticker of given financial institution. The graphs present the same set of data but with different positioning of the nodes.}	\label{fig:actual_network}
\end{figure}

The literature investigating the topological nature of the interbank market often provides evidence of the \textit{dis-assortative} property of the network. In graph theory, the term assortativity refers to the tendency of nodes to be connected with the nodes of similar characteristics. In the context of financial networks, the term of \textit{dis-assortative} property is often used with respect to different bank features. For example, based on the Brazilian interbank market, \cite{silva16} reports its dis-assortative property with respect to the number of connections of institutions\footnote{A similar reference is used e.g. in \cite{aldasoro17}} (node degree). The same property was observed on the Italian interbank market (\cite{bargigli15}). On the other hand, \cite{craig14} also provides evidence of dis-assortative behavior. However, in this case, with respect to the bank size (i.e. smaller banks are more likely to be connected to the big ones).

\begin{table}
	\center
	\begin{tabular}{lcc c cc}
		\hline
		& \multicolumn{2}{c}{2023} & & \multicolumn{2}{c}{2006}\\
		\cline{2-3} \cline{5-6} 
		\multicolumn{1}{l}{Network measures} & \multicolumn{1}{c}{Europe} & \multicolumn{1}{c}{US} && \multicolumn{1}{c}{US} & \multicolumn{1}{c}{Europe}\\
		\hline
		density & 0.0756 & 0.108 && 0.186 & 0.130 \\
		Average degree & 6.048 & 6.26 && 9.3 & 9.11 \\
		Median degree & 4 & 5 && 8 & 9 \\
		Excess degree assortativity & -0.373 & -0.324 && -0.324 & -0.245 \\
		Indegree assortativity & -0.188 & 0.137 && 0.1 & 0.162 \\
		Outderee assortativity & -0.31 & -0.0037 && -0.072 & 0.134 \\    
		Total degree assortativity & -0.2626 & -0.287 && -0.307 & -0.118 \\
		Cluster coefficient & 0.033 & 0.0459 && 0.078 & 0.053 \\
		intermediator share & 0.68 & 0.866 && 0.769 & 0.88 \\   
		Max path & 6 & 11 && 5 & 7 \\
		Relative max eigenvector centrality & 0.064 &  0.354 &&     0.221 & 0.163 \\
		Relative core size & 0.195 & 0.195 && 0.243 & 0.243 \\
		Absolute core size & 8 & 8 && 10 & 10 \\
		\hline
	\end{tabular}\
	\caption{Descriptive statistics of estimated networks. The definitions of each are described in appendix \ref{appendix:network_metrics}.}
	\label{table:network_metrics}
\end{table}

The assortativity, describing the correlation of nodes in/out-degree, is negative in almost every subsample of estimated networks, that is, they present dis-assortative properties with respect to their degree. The only type of assortativity that is mostly positive is the indegree assortativity (measuring the correlation between the indegree of the connected nodes). It's worth noting that the same pattern is present in some of the theoretical models (i.e. \cite{aldasoro17}). The negative values are expected. This is because the economic role of the interbank market is mostly to facilitate the flow of funds from banks with excess liquidity to those with funding needs. Thus, the banks are more likely connected with each other if their connections have, in overall, different directions of edges. As mentioned before, the empirical literature also reports mostly negative assortativity values.

The dis-assortative property of the financial network is closely related with the \textit{core-periphery} structure of the network (\cite{craig14}). This structure is commonly observed in the transaction level data of the interbank market and is a widely acknowledged stylized fact. The structure is present when there is a core of the network with (usually bigger) banks, intermediating the flow of funds among the smaller ones. The banks tend to trade between the core and a periphery, but not within those groups. The identified core of the structure is rather stable among the financial markets but changes a bit throughout time. Nevertheless, the relative size is considerably higher than the estimates from the literature. For example, the seminal paper (\cite{craig14}) identifying the structure reports its relative size to be 3\% (depending on the specification). The reason for such a wide difference is most likely due to the sample used. This work mostly uses data of global systematically important institutions, which are most likely part of the core of the financial network. Another factor might be the different methodology applied to identify the core-periphery structure and the network itself. 

\subsection{Dynamic connectedness}

As mentioned before, the connectedness measure described in the section \ref{section:fin_network} is calculated on a rolling window basis. That is, at each time $t$ the connectedness is calculated for the past window of observations up to $t - w$, where $w$ is a window length. The calculations are done with two window lengths of a quarter and a year. The resulting time series from the calculation are presented in figure \ref{figure:connect_ts}. The variables were standardized ($\frac{x - \bar{x}}{\sigma_{x}}$), in order to be comparable between each other (also during the modeling stage).

\begin{figure}
	\centering
	\includegraphics[scale = 0.76]{img/connect_ts.png}
	\caption{Connectedness time series of the US market. Rolling window of a quarter.}
	\label{figure:connect_ts}
\end{figure}

The Granger-based method provides the most distinct and volatile time series. The method also captures a different type of connectedness. As noted already, it controls the common exposures by introducing sectoral controls in the Granger regression. The other approaches are not controling exogenous variables (other than subtracting the banking index returns) and capturing a linear relationship between the rates of return. The similarity is also confirmed by the Pearson's correlation equal to 77\% between the eigendecomposition and Ledoit-Wolf methods. On the other hand, the Granger-based connectedness time series has only 15\% and 3\% correlation with respect to the eigendecomposition and Ledoit-Wolf methods respectively. The full correlation matrix between the connectedness time-series is shown on the figure \ref{figure:cor_matrix} in the appendix \ref{appendix:graphs_tables}.

\section{Regime-dependent effect of connectedness}\label{section:arch_model}

The previous section described in detail the methods of estimating the connectedness of the financial system. Now, the resulting time series of the connectedness of the system is going to be utilized in the next process of time-series modeling. As the theoretical contribution posits, connectedness should have a regime-dependent effect on the systemic stability of the financial sector. Thus, the econometric tool of choice is the Markov switching autoregressive conditional heteroskedasticity (ARCH) model. The class of models with Markov switching parameters was first proposed in the seminal work of \citet{hamilton89}, with the natural extension for ARCH effect in \citet{cai94}. Since then, these models have been the go-to approach for modeling a time-variation and regime-change in the regression model parameters. 

As in usual process of ARCH modeling, the model requires to specify the mean equation:

\begin{equation}
	r_{b,t} = \beta_0 + \sum_{i=1}^{k}\beta_i r_{b, t-i} + \sum_{j=0}^{p}\beta_{k+j} r_{m, t-j} + \epsilon_t	
\end{equation}

Where $r_{b,t}$ and $r_{m, t}$ are rates of returns for banking index and broad market at time $t$ respectively. Note, the broad market index is included as a covariate also at time $t$. The lags were chosen with the Akaike information criterion (\citet{akaike98}) to be three for both of the covariates. Subsequently, the absolute values of the residuals are modeled with a regime-switching model:


\begin{align}
	\label{equation:vol_model}
\sqrt{\epsilon^{2}_t} &= \alpha_{0,S_t} + \underbrace{\alpha_{1,S_t} \gamma_{t-1}}_{\text{connectedness}} + \underbrace{\sum_{i=1}^{p} \alpha_{i+1} \sqrt{\epsilon^2_{t-i}}}_{\text{lag controls}} + \vartheta_t \\
\vartheta \sim & \, \mathcal{N}(0, \eta)
\end{align}

Where $\gamma_t$ is, as before, financial connectedness at the time $t$\footnote{Of course, there are different connectedness variables, calculated with different methods, rolling window sizes and markets, but the indices are omitted for the sake of brevity.}. The lag covariates controlling for heteroskedasticity, which is oftentimes present in financial time-series. The error term of the volatility equation is normally distributed with zero mean and $\eta$ variance. It is worth noting, that despite the commonly observed fat-tailed behavior of the financial data, it is sufficient to use a normal distribution as the mixture of two distributions with different variances (for each market regime) will produce in the end a fat-tail like distribution (\citet{timmermann00}). Unlike in a standard ARCH model, the parameters $\alpha$ are unconstrained. The reason is that the model's purpose is not to predict the volatility but to investigate the regime-dependent effect of connectedness on systemic risk. Thus, it is more valuable to see if the coefficients are negative (or not), rather than eliminating the possibility of producing negative volatility when forecasting \footnote{A similar trade-off which occurs when deciding about logistic regression or linear probability model - risk of nonsensical predictions vs. ease of interpretability.}. An important assumption in the model is that the volatility (or the absolute rate of return) of the banking index is the appropriate proxy for the stability of the financial sector. There are some theoretical arguments that it may not always be the case (see e.g. the literature regarding the volatility paradox - \citet{brunnermeier14} or \citet{danielsson18}). Nonetheless it is still a commonly utilized proxy in the literature (some of the examples are \citet{nelson07}, \citet{bratis20}, \citet{imf08} or \citet{billio16}).

The $\gamma_{t-1}$ and the corresponding coefficient $\alpha_{1, S_t}$ are the relevant terms of interest to the research design. Notably, the connectedness time series is lagged by a single period. This operation is subtle yet crucial, as the instantaneous relationship between system stability and connectedness may not be fully exogenous. The connectedness measures, especially the one based on Ledoit-Wolf estimation, are still imperfect estimations and capture to some degree a simple correlation between stock returns. It is commonly acknowledged that the correlations increase also as a consequence of sudden volatility spikes. For example, due to the margin calls (\citet{kahraman19}) or fly to safety effects (\citet{baele19}). Additionally, the banks themselves may make hedging decisions in the face of market uncertainty, thus changing the connections between each other. In order to eliminate this source of endogeneity, the connectedness variables are lagged by a single period. With this specification, the model investigates how financial stability evolves under different connectedness levels prior to the arrival of the shock. Thanks to this operation, the coefficient has a causal interpretation. 

The parameters indexed by $S_t$ depends upon the latent (unobservable) state, that may take values from 1 to $K$. The parameters change their values depending on the state. The state $K$ is governed by the Markov process. The probability of transition from state $i$ to state $j$ is given by $K \times K$ left-stochastic transition matrix $\mathbf{P}$:

\begin{equation}
	\mathbf{P} = P(S_t = i | S_{t-1} = j) = 
	\begin{bmatrix}
		\pi_{1,1} & \pi_{1,2} & \cdots & \pi_{1,k} \\
		\pi_{2,1} & \pi_{2,2} & \cdots & \pi_{2,k} \\
		\vdots  & \vdots  & \ddots & \vdots  \\
		\pi_{k,1} & \pi_{k,2} & \cdots & \pi_{k,k} 
	\end{bmatrix}
\end{equation}

With standard constraints $\sum_{i}^{K} \pi_{i,j} = 1 \; \forall j \in \{1,\cdot, K\}$ and $0 \geq \pi_{i,j} \geq 1 \; \forall i,j \in \{1,\cdot, K\}$. For the state size $K=2$, which is the case for herein model, the constraint for the transition matrix may be easily imposed with following parametrization:

\begin{equation}
	P(S_t = i | S_{t-1} = j) = \begin{bmatrix}
		\pi_1 & 1 - \pi_2\\
		1 - \pi_1 & \pi_2
	\end{bmatrix}
\end{equation}

Because of the latent nature of the regimes, the maximum likelihood estimation of the model is relatively complex. The objective function is not solvable analytically but is reasonably easy to optimize with gradient-based methods\footnote{The initial parameters without an exact transition matrix are found with Expectations-Maximization algorithm (\citet{dempster77}) and the actual Markov switching likelihood is maximized with the gradient-based method (\citet{rowan90})}. Although computationally manageable, increasing the number of parameters (say, by adding regime-switching covariates or increasing the number of states) poses a risk of reaching a local maximum. Hence, the model specification is maintained sufficiently concise.

Appendix \ref{appendix:technical} elaborates on technical details of the implementation and provides a source to reproduce the research.

\section{Main results}\label{section:main_results}

The model described in the previous section was estimated based on data from both markets and with various specifications. Tables \ref{table:model63} and \ref{table:model256} present the selected parameters from the various model specifications for window sizes of a quarter and a year respectively. Due to the number of the models and their parameters, the other information regarding them (e.g. estimated coefficients for lag covariates) is shown in appendix \ref{appendix:model_params}. The tables \ref{table:model63} and \ref{table:model256} present four parameters from equation \ref{equation:vol_model} for each of the regimes. The corresponding standard errors are computed based on the inverse of the Hessian matrix produced from the likelihood optimization.

As described in the section \ref{section:introduction}, there are particular results we should expect according to the theory. Firs of all, \citet{acemoglu15} suggest that the connectedness of the system should have a regime-dependent effect on the financial stability. In order to capture this regime-dependence, the model would need to distinguish two regimes (this is by design) but with varying degrees of volatility, ideally both indicated by different intercept and variance of error. A higher intercept suggests that particular regime specific regression has the best fit around higher level of volatility. On the other hand an increased error of variance indicates frequent changes in volatility itself, i.e. an elevated volatility of volatility. Another key theoretical result is the direction of the effect within the regimes. In case of low shock regime, the more dense connection between the financial institutions is able to more easily absorb the impact. In the context of the empirical model, this should translate to the negative sign of the $\alpha_{1, S_t = \text{low shock}}$ parameter from equation \ref{equation:vol_model} (i.e. negative relationship between connectedness and volatility). Once the shock is above some magnitude, the connectedness shall have a damaging effect. The regime switch is present e.g. due to the first defaults, initiating a domino effect via credit risk or because of the margin calls, which force market participants to sell their assets further dampening the prices. This mechanism implies that the $\alpha_{1, S_t = \text{high shock}}$ effect should have a positive sign.

Once the expected by the theory outcome is described it is now appropriate to contrast the estimates results with the theory. The model is able to clearly distinguish two regimes of stable and unstable markets (or alternatively, low and high shock). Regime 1 has a lower intercept, hence it describes the financial system under low volatility.   For example, the model for US data using the Ledoit-Wolf connectedness estimated a model with an intercept of 0.37 and 1.342 for two regimes\footnote{Considering that time series are multiplied by 100, the values correspond to the 0.37\% and 1.342\% of volatility under zero values for other covariates.}. All the other models have substantial differences between the intercepts at different regimes. As may be concluded from the diagonal values of the transition matrix $\pi_{i,i}$, the stable markets are always more persistent. For example, the model for US data with Eigenvalue-based connectedness has a transition probability from a stable markets regime equal to 82.3\%. This is the chance of staying in the same regime over the next period. The persistance of the regimes is aligned with a commonly observed behavior of financial markets, which are more often than not calm\footnote{Although, one may argue that the unstable market is less common by definition.}. Since none of the transition probabilities are substantially high (e.g. above 90\%) the identified regimes are in general switched relatively often. In fact, a regime in one of the models has transition probability below 50\% suggesting that it is less probable to stay in the same state in the upcoming period. The stable markets also have a smaller variance of error term $\eta$ (a volatility of volatility), further confirming the distinction between the stable and unstable regimes. 

\begin{table}\small
	\begin{tabular}{cccccc | cccccc}
		& \multicolumn{5}{c}{US} & \multicolumn{4}{c}{EU} \\
		Measure &  & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} \\
		%\cmidrule(lr){1-6}
		\hline
		& & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. \\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Ledoit-Wolf} & $\alpha_0$ & 0.374 & 0.013 & 1.385 & 0.038 & 0.441 & 0.019 & 1.82 & 0.05\\
		& $\alpha_1$ & 0.015* & 0.006 & 0.155* & 0.029 & 0.019 & 0.01 & 0.302* & 0.036\\
		& $\eta$ & 0.326 & 0.007 & 0.935 & 0.01 & 0.401 & 0.009 & 1.209 & 0.011\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{82.4\%} & \multicolumn{2}{c|}{61.1\%} & \multicolumn{2}{c}{73.52\%} & \multicolumn{2}{c}{48.16\%}\\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Eigenvalue} & $\alpha_0$ & 0.377 & 0.014 & 1.382 & 0.039 & 0.434* & 0.017 & 1.829* & 0.048\\
		& $\alpha_1$ & 0.02* & 0.007 & 0.136* & 0.029 & -0.013 & 0.008 & 0.303* & 0.043\\
		& $\eta$ & 0.327 & 0.007 & 0.939 & 0.01 & 0.49 & 0.008 & 1.22 & 0.11\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{82.3\%} & \multicolumn{2}{c|}{67.2\%} & \multicolumn{2}{c}{74.8\%} & \multicolumn{2}{c}{60.8\%}\\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Granger} & $\alpha_0$ & 0.373* & 0.013 & 1.392* & 0.039 & 0.445* & 0.018 & 1.824* & 0.05  \\
		& $\alpha_1$ & 0.018* & 0.006 & 0.08 & 0.027 & 0.018 & 0.01 & 0.276* & 0.033 \\
		& $\eta$ & 0.328 & 0.007 & 0.949 & 0.01 & 0.401 & 0.009 & 1.215 & 0.011\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{83.39\%} & \multicolumn{2}{c|}{62.91\%}& \multicolumn{2}{c}{74.56\%} & \multicolumn{2}{c}{50.76\%}\\
		\hline
	\end{tabular}
	\caption{Model estimation results for rolling window size of quarter (63 trading days). Full model parameters in the appendix \ref{appendix:model_params}. * coefficient with 5\% statistical significance.}
	\label{table:model63}
\end{table}

The estimated coefficients confirm the conjecture of the \citet{acemoglu13} and \citet{haldane13}, at least to some extent. The coefficient $\alpha_1$ corresponds to the main variable of interest, i.e. the connectedness of the system. The values of the parameters are almost always significantly positive \footnote{except the model for the US market with Granger-based connectedness.}. For example, on the European market and a window size of a quarter, a one standard deviation increase in connectedness results in volatility higher by around 0.3 percentage point during the unstable market (or high shock) regime. It is evident that connectedness has a regime-dependent effect on financial stability. Just as described in the work of \citet{acemoglu13}, during the unstable market regime (or in the original work terms - a high shock regime), connectedness amplifies the shock and increases the volatility of the system. 

On the other hand, the behavior under the stable markets regime is less aligned with the theory. The connectedness, although in some cases significant, is never economically sizeable in terms of the effect. Most corresponding coefficients are around 0.02, suggesting a connectedness higher by one standard deviation should result in volatility higher of around 0.02 percentage points. The value is virtually negligible. This is in contrast to the robust-yet-fragile theory, that posits an improvement in terms of financial stability due to higher connectedness of the market participants.

\begin{table}\small
	\begin{tabular}{cccccc | cccccc}
		& \multicolumn{5}{c}{US} & \multicolumn{4}{c}{EU} \\
		Measure &  & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} \\
		%\cmidrule(lr){1-6}
		\hline
		& & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. \\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Ledoit-Wolf} & $\alpha_0$ & 0.37 & 0.013 & 1.342 & 0.037 & 0.458 & 0.018 & 1.874 & 0.053\\
		& $\alpha_1$ & 0.014* & 0.006 & 0.226* & 0.026 & 0.034 & 0.009 & 0.194 & 0.038\\
		& $\eta$ & 0.319 & 0.007 & 0.888 & 0.009 & 0.409 & 0.008 & 1.246 & 0.011\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{80.64\%} & \multicolumn{2}{c|}{57.8\%} & \multicolumn{2}{c}{76.07\%} & \multicolumn{2}{c}{50.8\%}\\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Eigenvalue} & $\alpha_0$ & 0.378 & 0.014 & 1.337 & 0.0378 & 0.441 & 0.018 & 1.871 & 0.053\\
		& $\alpha_1$ & 0.025* & 0.007 & 0.222* & 0.028 & -0.009 & 0.008 & 0.035 & 0.045\\
		& $\eta$ & 0.319 & 0.007 & 0.89 & 0.01 & 0.41 & 0.008 & 1.261 & 0.011\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{80.33\%} & \multicolumn{2}{c|}{57\%} & \multicolumn{2}{c}{77.13\%} & \multicolumn{2}{c}{53.2\%}\\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Granger} & $\alpha_0$ & 0.375 & 0.013 & 1.352 & 0.036 & 0.463 & 0.018 & 1.861 & 0.05\\
		& $\alpha_1$ & 0.019 & 0.007 & 0.197 & 0.024 & 0.044 & 0.01 & 0.294 & 0.037\\
		& $\eta$ & 0.316 & 0.007 & 0.889 & 0.009 & 0.404 & 0.008 & 1.22 & 0.011\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{80.72\%} & \multicolumn{2}{c|}{58.84\%}& \multicolumn{2}{c}{75.16\%} & \multicolumn{2}{c}{50.28\%}\\
		\hline
	\end{tabular}
	\caption{Model estimation results for rolling window size of quarter (256 trading days). Full model parameters in the appendix \ref{appendix:model_params}. * coefficient with 5\% statistical significance.}
	\label{table:model256}
\end{table}

\section{Robustness check}\label{section:robustness}

In order to investigate the role of firm-specific variables in driving the main results, the model was extended for balance sheet and PnL data of the financial institutions. Specifically the following financial statement items are used: total assets, net interest income, deposits, interbank assets and liabilites. Naturally, incorporating this kind of data is not costless for the research design. The universe of institutions had to be shrunk, as well as the size of the time series. Thus, the following exercise is left as a robustness check.

\subsection{Data}

The data was sourced from the Orbis dataset spanning seven and a half year starting from the third quarter of 2016 up to fiscal year of 2023 \footnote{the oldest possible data to download from the Orbis website}. Due to the incomplete dataset, the number of financial intermediaries analyzed is reduced to 31 for the European market. The institutions left are listed in the Appendix \ref{appendix:data}, table \ref{table:ipo}. The financial variables are denominated in EUR based on the exchange rate at the end of the corresponding fiscal period. Table \ref{table:orbis_descriptive} presents some descriptive statistics of the financial data. The last two firm characteristics from the table and a natural logarithm of assets were used in the modeling part as exogenous variables.

\begin{table}
	\centering
	\begin{tabular}{lrrrrr}
		\hline
		Variable & Mean & Median & Std Dev & Minimum & Maximum \\
		\hline
		Assets & 403,288,031 & 265,337,983 & 431,680,746 & 23,076,398 & 1,748,295,895 \\
		IB Assets & 19,134,891 & 8,878,950 & 25,601,625 & 967,511 & 92,904,796 \\
		IB Liabilities & 43,925,992 & 22,018,866 & 55,708,873 & 998,750 & 209,368,622 \\
		Operating Income & 5,471,043 & 2,885,447 & 6,565,259 & 409,057 & 31,875,663 \\
		ROA & 0.0155 & 0.0136 & 0.0069 & 0.0064 & 0.0327 \\
		IB Assets/Liabilites & 1.0646 & 0.4691 & 2.2903 & 0.0928 & 11.7987 \\
		\hline
	\end{tabular}
	\caption{Descriptive statistics of Orbis data for European financial intermediaries.  Nominal values in EUR. "IB" refers to interbank market. FY2023.}
	\label{table:orbis_descriptive}
\end{table}

\subsection{Modeling adjustment}

Other than the data limitation, the introduction of fiscal data requires a matching time series to the daily stock returns. In order to increase the frequency of the data, the quarterly financial variables were interpolated into a weekly frequency\footnote{This is a common procedure in financial econometric literature when incorporating time series with different frequencies. The interpolation is done in a similar manner as in \citet{hautsch14a} and \citet{hautsch14}}. The stock returns, on the other hand, were compounded into weekly returns. The resulting modeling frequency is a compromise between the reasonable size of the resulting dataset and the information content of the variables. The size thereof used to estimate the model is equal to 312 observations. However, the initial period of window size is omitted due to lack of a corresponding connectedness time-series. The window is changed as well (to 56 and 84 weeks), since the previous size of a quarter would be too small for meaningful inference. The financial data was interpolated with piecewise cubic polynomial. The figure \ref{figure:interpolation} in appendix \ref{appendix:robustness} presents an example of interpolated data and an actual one. The same appendix elaborates on statistical properties of the interpolated data with respect to the original one.

The only connectedness method flexible enough for introducing the exogenous, firm-specific variables is the one based on Granger causality. This is because both Ledoit-Wolf method and Eigendecomposition method are based on covariance, which unables is unfit for multivariate analysis of particular connections. Specifically, the equation \ref{equation:granger} was extended by the additional covariates:

\begin{equation}
	r_{i,t+1} = \beta_0 + \beta_1 r_{j,t} + \beta_2 r_{i, t} + \underbrace{\beta_3 \log{A}_t + \beta_4 \text{ROA}_t + \beta_5 \frac{\text{IB Assets}_t}{\text{IB liab.}_t} + \beta_6 \frac{\text{D}_t}{\text{A}_t}}_{\text{New balance sheet data of institution $i$}} + \underbrace{\sum_{i=1}^{k} \beta_{i+5} x_{t}}_{\text{Sectoral controls}} +\epsilon_t
\end{equation}

The regression now controls for firm-specific financial data when identifying the link between the pair of financial institutions $i$ and $j$. With $A_t$ being total assets, $\text{ROA}_t$ the return on assets, $\text{IB}$ stands for interbank and $\text{D}$ are deposits at time $t$ for the institution $i$. The above covariates should control for the firm-specific common characteristics between the institutions. For example, deposit share reflects the business model of particular financial institution. A low share of deposits may indicate a more services-oriented business model (e.g. investment banks like Goldman Sachs). This would control for the shocks to specific industry or business lines (e.g. investment banking). The resulting connectedness time series for both of the window sizes is presented in figure \ref{figure:connect_bs}. The main event driving the connectedness was clearly related to the COVID-19 health crisis. The rest of the procedure is as before, the regime switching ARCH specification is otherwise as described in the equation \ref{equation:vol_model}.

\begin{figure}
	\centering
	\includegraphics[scale = 0.9]{img/connect_bs.png}
	\caption{Connectedness time series of the EU market with balance sheet and PnL information.}
	\label{figure:connect_bs}
\end{figure}

\subsection{Results}

The results of model estimates for window sizes of 56 (a year) and 84 (year and a half) weeks are presented in table \ref{table:model_robust}. The estimates confirm the main results. The model clearly distinguishes between two regimes with elevated volatility and standard market conditions. The coefficients corresponding to the connectedness between these regimes vary. As before, connectedness is an amplifying mechanism of instability for the financial sector, but only during the high shock regime. On the other hand, the direction of the effect during the stable regime is unexpected. With the coefficient being insignificant and slightly (what's more surprising) positive. The differences of these results with respect to the main ones are also due to the increase in frequency, which resulted in higher intercept and $\eta$ parameters.  

\begin{table}\small
	\begin{tabular}{cccccc | cccccc}
		& \multicolumn{5}{c}{Window size: 56 weeks} & \multicolumn{4}{c}{Window size: 84 week} \\
		Measure &  & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} & \multicolumn{2}{c}{\bfseries Regime 1} & \multicolumn{2}{c}{\bfseries Regime 2} \\
		%\cmidrule(lr){1-6}
		\hline
		& & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. & Estimate & S.E. \\
		\hline
		\multirow{3}{*}[\normalbaselineskip]{Granger} & $\alpha_0$ & 1.524* & 0.19 & 5.031* & 0.53 & 1.511* & 0.206 & 5.078* & 0.564 \\
		& $\alpha_1$ & 0.129 & 0.093 & 1.175* & 0.534 & 0.187 & 0.104 & 0.925* & 0.489\\
		& $\eta$ & 1.013* & 0.045 & 2.872* & 0.086 & 0.979* & 0.049 & 2.924* & 0.086\\
		& $\pi_{i,i}$ &  \multicolumn{2}{c}{80.36\%} & \multicolumn{2}{c|}{51.85\%} & \multicolumn{2}{c}{76.53\%} & \multicolumn{2}{c}{49.76\%}\\
		\hline
	\end{tabular}
	\caption{Model estimates for model with Granger-based connectedness and with incorporated financial data. Data for European financial market.* coefficient with 5\% statistical significance.}
	\label{table:model_robust}
\end{table}

\section{Concluding remarks}\label{section:conclusion}

The economic theory thoroughly described and modeled the conjecture of \citet{haldane13} through the lens of financial network theory. The models suggested e.g. in \citet{acemoglu13} provided a theory in which connectedness in the financial sector has a regime-dependent effect on the stability thereof. According to the work, more dense networks may diversify and spread the shock of a relatively small magnitude. On the other hand, once the shock is above some threshold, the effect of connectedness changes substantially. The shock is transmitted further into the network with more financial intermediaries being affected.

This work presented a first empirical evidence of this regime-dependent effect of connectedness on financial stability. The research design allowing us to test these phenomena was a two step process. First, the connectedness of the financial system was estimated based on various, well established methods from the literature. The rolling-window estimation produced a time series describing how interconnectedness changes through time. In the next step, the produced time-series was used as an exogenous variable in a Markov-switching ARCH model. The estimated coefficients of the model allow us to see how the effect of connectedness changes, depending on the regime. The research design also includes a robustness check with a balance sheet and profit and loss information of the financial intermediaries. The robustness check further confirms the main results.

The evidence of the research is mixed. The effect of connectedness on financial stability is substantially asymmetric. During the higher shock regime, the more connected the system is, the more volatility it suffers once the shock arrives. The second part of the results, less aligned with the theory, is that during a calm market regime connectedness does not play a significant role in the contagion dynamics. The asymmetry may be explained by the \textit{financial network externality} described in \citet{acemoglu15}. According to which, the overall connectedness has a damaging effect on the system because the market participants are not internalizing the consequences of credit risk on other parts of the network, not directly related to thereof.

\bibliography{bibliography}

\newpage

\appendix

\section{Data}\label{appendix:data}

\begin{table}[!htbp]
	\begin{center}
		\renewcommand{\arraystretch}{0.8}
		\resizebox{\textwidth}{!}{\begin{tabular}{c|c||c |c|c}\multicolumn{2}{c||}{USA} & \multicolumn{2}{c}{EU} \\
			\hline \hline 
			Ticker & Name & Ticker & Name & Country \\
			\hline \hline
			BAC & Bank of America Corporation & EBO & Erste Group Bank AG & Austria \\
			\hline
			BK & The Bank of New York Mellon & RAW & Raiffeisen Bank AG & Austria\\
			\hline
			BCS & Barclays* & KBC & KBC Group & Belgium\\
			\hline
			BMO & Bank of Montreal* & CBK & Commerzbank AG & Germany \\
			\hline
			COF & Capital One Financial Corporation & DBK & Deutsche Bank AG & Germany \\
			\hline
			SCHW & The Charles Schwab Corporation & NDA-SE & Nordea & Finland \\
			\hline
			C & Citigroup & DANSKE & Danske Bank A/S & Denmark \\
			\hline
			CFG & Citizens Financial Group & JYSK & Jyske Bank A/S & Denmark \\
			\hline
			DB & Deutsche Bank* & SYDB & Sydbank A/S & Denmark \\
			\hline
			GS & The Goldman Sachs Group & BBVA & Banco Bilbao Vizcaya & Spain \\
			\hline
			JPM & JPMorgan Chase \& Co. & BKT & Bankinter SA & Spain \\
			\hline
			MTB & M\&T Bank Corporation & CABK & CaixaBank SA & Spain \\
			\hline
			MS & Morgan Stanley & SAB & Banco de Sabadell SA & Spain \\
			\hline
			NTRS & Northern Trust Corporation & SAN & Banco Santander SA & Spain \\
			\hline
			PNC & The PNC Financial Services Group & UNI & Unicaja Banco SA & Spain \\
			\hline
			STT & State Street Corporation & BNP &  BNP Paribas SA & France \\
			\hline
			TD & The Toronto Dominion Bank* & ACA & Crédit Agricole SA & France \\
			\hline
			TFC & Truist Financial Corporation & GLE & Société Générale & France \\
			\hline
			UBS & UBS Group AG* & ALPHA & Alpha Services and Holdings SA & Greece \\
			\hline
			WFC & Wells Fargo \& Company & EUROB & Eurobank Ergasias & Greece \\
			\hline
			ALLY & Ally Financial Inc. & ETE & National Bank of Greece SA & Greece \\
			\hline
			AXP & American Express Company & TPEIR & Piraeus Financial Holdings SA & Greece \\
			\hline
			DFS & Discover Financial Services & OTP & OTP Bank Nyrt & Hungary \\
			\hline
			FITB & Fifth Third Bancorp & A5G & AIB Group plc & Ireland \\
			\hline
			HSBC & HSBC Holdings plc* & BARC & Barclays PLC & Great Britain \\
			\hline
			HBAN & Huntington Bancshares Incorporated & BARC & Barclays PLC & Great Britain \\
			\hline
			KEY & KeyCorp Bank & BIRG & Bank of Ireland Group & Ireland \\
			\hline
			MUFG & Mitsubishi UFJ Financial Group* & BAMI & Banco BPM S.p.A. & Italy \\
			\hline 
			PNC & The PNC Financial Services Group & ISP & Intesa Sanpaolo S.p.A. & Italy \\
			\hline
			RF & Regions Financial Corporation & MB & Mediobanca Banca di Credito Finanziario S.p.A. & Italy \\
			\hline
			SAN & Banco Santander, S.A.* & BMPS & Banca Monte dei Paschi di Siena S.p.A. & Italy \\
			\hline
			& & BPE & BPER Banca S.p.A. & Italy \\
			\hline
			& & UCG & UniCredit S.p.A. & Italy \\
			\hline
			& & ABN & ABN AMRO Bank N.V. & Netherlands \\
			\hline
			& & INGA & ING Groep N.V. & Netherlands \\
			\hline
			& & DNB & DNB Bank ASA & Norway \\
			\hline
			& & PKO & Powszechna Kasa Oszczednosci Bank Polski S.A. & Poland \\
			\hline
			& & PEO & Bank Polska Kasa Opieki S.A. & Poland \\
			\hline
			& & BCP & Banco Comercial Português S.A. & Portugal \\
			\hline
			& & SEB-A & Skandinaviska Enskilda Banken AB & Sweden \\
			\hline
			& & SHB-A & Svenska Handelsbanken AB & Sweden \\
			\hline
			& & SWED-A & Swedbank AB & Sweden
		\end{tabular}}
	\end{center}
	\caption{List of the banks analyzed. *These banks are not registered in USA but are apparently systematically important to the local market according to the regulator. }
	\label{table:bank_list}
\end{table}

% latex table generated in R 4.3.2 by xtable 1.8-4 package
% Sat Jul 20 14:54:42 2024
\begin{table}[!htbp]
	\centering
	\renewcommand{\arraystretch}{0.7}
	\begin{tabular}{l|l|l|l}\multicolumn{2}{c|}{USA} & \multicolumn{2}{c}{EU} \\
		\hline
		Ticker & IPO date & Ticker & IPO date \\ 
		\hline 
		ALLY & 2014-01-29 & A5G & 2000-01-06 \\ 
		AXP & 2000-01-06 & ABN & 2015-11-23 \\ 
		BAC & 2000-01-06 & ACA & 2001-12-17 \\ 
		BCS & 2000-01-06 & ALPHA & 2000-01-06 \\ 
		BK & 2000-01-06 & BAMI & 2000-01-06 \\ 
		BMO & 2000-01-06 & BARC & 2000-01-06 \\ 
		C & 2000-01-06 & BBVA & 2000-01-06 \\ 
		CFG & 2014-09-25 & BCP & 2000-01-06 \\ 
		COF & 2000-01-06 & BIRG & 2001-07-16 \\ 
		DB & 2000-01-06 & BKT & 2000-01-06 \\ 
		DFS & 2007-06-15 & BMPS & 2000-01-06 \\ 
		FITB & 2000-01-06 & BNP & 2000-01-06 \\ 
		GS & 2000-01-06 & BPE & 2000-01-06 \\ 
		HBAN & 2000-01-06 & CABK & 2007-10-11 \\ 
		HSBC & 2000-01-06 & CBK & 2000-01-06 \\ 
		JPM & 2000-01-06 & DANSKE & 2000-11-09 \\ 
		KEY & 2000-01-06 & DBK & 2000-01-06 \\ 
		MS & 2000-01-06 & DNB & 2000-01-06 \\ 
		MTB & 2000-01-06 & EBO & 2009-03-31 \\ 
		MUFG & 2001-04-03 & ETE & 2000-01-06 \\ 
		NTRS & 2000-01-06 & EUROB & 2000-01-06 \\ 
		Open & 2000-01-06 & GLE & 2000-01-06 \\ 
		PNC & 2000-01-06 & INGA & 2000-01-06 \\ 
		RF & 2000-01-06 & ISP & 2000-01-06 \\ 
		SAN & 2000-01-06 & JYSK & 2004-10-05 \\ 
		SCHW & 2000-01-06 & KBC & 2000-01-06 \\ 
		STT & 2000-01-06 & MB & 2000-01-06 \\ 
		TD & 2000-01-06 & NDA & 2000-01-06 \\ 
		TFC & 2000-01-06 & OTP & 2002-03-06 \\ 
		UBS & 2000-05-17 & PEO & 2000-01-06 \\ 
		&  & PKO & 2004-11-11 \\ 
		&  & RAW & 2010-08-17 \\ 
		&  & SAB & 2000-01-06 \\ 
		&  & SAN & 2000-01-06 \\ 
		&  & SEB & 2000-01-06 \\ 
		&  & SHB & 2000-01-06 \\ 
		&  & SWED & 2000-01-06 \\ 
		&  & SYDB & 2000-01-06 \\ 
		&  & TPEIR & 2000-01-06 \\ 
		&  & UCG & 2000-01-06 \\ 
		&  & UNI & 2017-07-03 
	\end{tabular}
		\caption{First available data for each of the stock prices. }
	\label{table:ipo}
\end{table}

\section{Network metrics}\label{appendix:network_metrics}

We define a graph $G = (V, E)$ to be an abstract object with a set of $E$ edges (or links) and a set of $V$ vertices (or nodes). The nodes are connected with edges in a graph. The node set $V$ and a set of edges $E$ is denoted as $V(G)$ and $E(G)$. The cardinality of these sets are usually denoted as $m = |E|$ for edges and $n = |V|$ for nodes. The edges may be represented by the nodes they connect - $(u, v)$ (or with shorthand notation $uv$). In case of directed graph, the order of the notation matters, as it defines the direction of the edge ($uv \neq vu$). For the weighted graph, the values associated to the nodes may be represented as a function $\omega : E \rightarrow \mathcal{R}$, assigning each edge $e \in E$ a weight $\omega(e)$. In case of the financial networks, the values may describe e.g. the exposure of the bilateral contractual obligation between the financial intermediaries. The undirected graphs are equivalent to the weighted ones with a unit edge weights $\omega(e) = 1 \; \forall \; e \in E$.

Degree, denoted as $d(v)$ is the number of edges of particular node $v$. For a directed graph, the \textit{out-degree} of $v \in V$ is denoted as $d^{+}(v)$, define the number of edges with the origin $v$. Analogically, the \textit{in-degree} is denoted as $d^{-}(v)$ is the number of the edges with destination at $v$.

As mentioned in the subsection $\ref{section:fin_network}$, the graph theory has a very appealing relation to the linear algebra. Every graph may be represented by its adjacency matrix, often denoted $\mathbf{A}$. In case of unweighted, directed graph, the adjacency matrix has values $a_{i,j} \in \{0,1\}$, indicating a node connection. That is, $a_{i,j} = 1 \Rightarrow i \rightarrow j \; \forall \;  i \neq j$. The matrix elements may take other values in case of the weighted graph. 

\subsection{Graph statistics definition}

\textbf{Network density} measures the connectedness of the network. The statistic is defined as:

\begin{equation}
	\gamma(G) \coloneqq \frac{m}{{n \choose 2}}
\end{equation}

\textbf{Average degree} is simply the average number of edges for each of the node in the graph:

\begin{equation}
	\bar{d}(G) = \frac{1}{n} \sum_{v \in V} d(v)
\end{equation}

The \textbf{median degree} is defined in a corresponding fashion.

The \textbf{assortativity} measures the correlation among the connected nodes with respect to their characteristics. It's calculation follows the Pearson correlation coefficient:

\begin{equation}
	r(G) = \frac{\sum_{uv \in E}^{m} (d(u) - \bar{d}(G)) (d(v) - \bar{d}(G))}{\sqrt{\sum_{uv \in E}^{m} (d(u) - \bar{d}(G))^2} \sqrt{\sum_{uv \in E}^{m} (d(v) - \bar{d}(G))^2}} \;, E \in G
\end{equation}

Naturally, as for the Pearson's correlation, it takes values between -1 and 1 and is interpreted in the same way as well. Depending on type of the assortativity, the correlation may be calculated based on other measure than degree of the node ($d(u)$). The excess degree assortativity is defined as in \cite{newman02} and uses outdegree value for source node $u$ and indegree for destination node $v$.

The \textbf{clustering coefficient} measure the relative amount of clusters. It is calculated as a share of closed triplets in total number of possible triplets of the graph. The closed triplet, being a three connected nodes. The calculation is easily defined with a matrix notation:

\begin{equation}
	C(\mathbf{A}) = \frac{\sum_{i}^{n} \sum_{j}^{n} \sum_{k}^{n} a_{i,j} a_{j,k} a_{k,i}}{\frac{1}{2} \sum_{i}^{n} k_i (k_i - 1)}
\end{equation}

Where $k_i = \sum_{j}^{n} a_{i,j}$. 

The \textbf{intermediator share} is simply a share of nodes with both indegree and outdegree:

\begin{equation}
	\frac{1}{n} \sum_{v \in V}^{n} \min\{1, \, d^{+}(v) d^{-}(v)\}
\end{equation}

The \textbf{maximum path} is the biggest set (in sense of cardinality) of distinct edges connecting nodes for every pair of the nodes. 

The \textbf{relative max eigenvector centrality} is a share of the node with the highest eigenvector centrality in the total sum of the centrality measures in the whole graph. The eigenvector centrality $c$ satisfies the following equation:

\begin{equation}
	\lambda c_i = \sum_{j \neq i}^{n} a_{j,i} c_j
\end{equation}

Or alternatively in the matrix formulation:

\begin{equation}
	\lambda \mathbf{c} = \mathbf{A}' \mathbf{c}
\end{equation}

The euqation may be solved as described in the subsection \ref{subsection:pca}. The appealing property of the measure is that the centrality of the node $i$ is proportional to the centrality of its directly neighboring nodes\footnote{It is clear when the change of the index of $c$ at the R.H.S. is spotted}. Additionally, the node may be central in the system either through the number of neighbors or the value of their centrality.

\subsection{Graphs and tables}\label{appendix:graphs_tables}

\begin{figure}[!htbp]
	\centering
	\subfloat[\centering Circle representation of graph]{{\includegraphics[width=7cm, height=7cm]{img/graph_us_circl.png} }}
	\quad
	\subfloat[\centering Circle representation of graph]{{\includegraphics[width=7cm, height=7cm]{img/graph_us.png} }}\\
	
	%	\subfloat[\centering Representation with random position]{{\includegraphics[width=7cm, height=7cm]{img/graph_us.png} }}
	%	\quad	
	%	\subfloat[\centering Circle representation of graph]{{\includegraphics[width=7cm, height=7cm]{img/graph_us_circl.png} }}
	
	\caption{Financial network visualization based on the US market data from 2023. Each point (node) represents a financial institution and the connections (edges) are estimated links.}	\label{fig:actual_network}
\end{figure}

\begin{figure}[!htbp]
		\centering
	\subfloat[\centering Circle representation of EU financial network]{{\includegraphics[width=7cm, height=7cm]{img/graph_eu_lw_circl.png} }}
	\quad
	\subfloat[\centering EU financial network representation with random position]{{\includegraphics[width=7cm, height=7cm]{img/graph_eu_lw.png} }}\\
	
	\subfloat[\centering US financial network representation with random position]{{\includegraphics[width=7cm, height=7cm]{img/graph_us_lw.png} }}
	\quad	
	\subfloat[\centering Circle representation of US financial network]{{\includegraphics[width=7cm, height=7cm]{img/graph_us_lw_circl.png} }}
	
	\caption{Graph visualization based on the data from 2023. Each point (node) represents a financial institution and the connections (edges) are estimated links. The network is estimated with the Ledoit-Wolf covariance estimator. The nodes are assumed to be connected if the estimated covariance exceeds 0.02\%}	\label{fig:actual_network_lw}
\end{figure}

\begin{table}[!htbp]
	\center
	\begin{tabular}{l |c|c}
		Metric & EU & US \\
		\hline
		Density & 0.117 & 0.135 \\
		Average degree & 9.36 & 7.86 \\
		Median degree & 8 & 3 \\
		Assortativity & -0.485 & -0.372 \\
		Cluster coefficient & 0.105 & 0.162 \\
		Intermediator share & 0.682 & 0.633 \\
		Max path & 3 & 4 \\
		Eigenvector centrality & 0.109 & 0.121 \\
		Core size (\%) & 17.07 & 19.51 \\
		Absolute core size & 7 & 8 \\
	\end{tabular}
	\label{table:lw_stats}
	\caption{Network metrics of financial network estimated with Ledoit-Wolf shrinkage method. Data from 2023}
\end{table}

\begin{figure}
	\centering
	\includegraphics[scale = 0.8]{img/connect_ts_app.png}
	\caption{Connectedness time series}
	\label{figure:connect_ts_app}
\end{figure}


\begin{table}[ht]
	\begin{center}
		\begin{tabular}{cc|ccccccc}
			Window size: & & \multicolumn{3}{c}{63} & & \multicolumn{3}{c}{256}\\
			\multirow{4}{*}{63} & Method: & LW & PCA & Granger & & LW & PCA & Granger\\
			\hline
			& LW & 1.00 & 0.77 & 0.03 && 0.59 & 0.57 & 0.17 \\
			& PCA & 0.77 & 1.00 & 0.16 && 0.29 & 0.77 & 0.23  \\
			& Granger & 0.03 & 0.16 & 1.00 && -0.15 & 0.07 & 0.45 \\
			&&&&&&&&\\
			\multirow{3}{*}{256} & LW  & 0.59 & 0.29 & -0.15 && 1.00 & 0.65 & 0.12 \\
			  & PCA & 0.57 & 0.66 & 0.07 && 0.65 & 1.00 & 0.28 \\
			  & Granger & 0.17 & 0.23 & 0.45 && 0.12 & 0.28 & 1.00 \\
		\end{tabular}
	\end{center}
	\caption{Pearson correlation matrix among the different specifications of connectedness time series}
	\label{figure:cor_matrix}
\end{table}

\section{Technical details}\label{appendix:technical}

Importing data and some elements of its preprocessing was done with Python programming language version 3.12.2. With packages yfinance, NumPy (\citet{harris20}) and pandas (\citet{reback20}). The connectedness estimation was computationally expensive\footnote{For example, the granger based method required fitting, at each point in time (around 6,000 observations) a multivariate regression among every combination of 42 stocks.}, thus it was done with Julia programming language 1.10.1 version (\citet{bezanson17}). The packages used were: DataFrames.jl for data analysis (\citet{kaminski23}), Graphs.jl for graph handling (\citet{fairbanks21}) and MarSwitching.jl for estimation of Markov switching model (\citet{dadej24}). The data visualization and descriptive statistics were don in R programming language version 4.3.2 (\citet{rcore23}). The repository with the source code and instructions to reproduce the research is available \href{https://github.com/m-dadej/robust\_fragile}{\underline{here}}.

\section{Full model estimation results}\label{appendix:model_params}
[The tables will be added soon]

\section{Robustness check details}\label{appendix:robustness}

The table \ref{table:interpolation_error} presents mean absolute relative error between chosen moments of interpolated and original time-series across financial institutions. The measure is calculated in a following way:

\begin{equation}
	\frac{1}{n} \sum_{i}^{n} \frac{\sqrt{(x_i - y_i)^2}}{x_i} 
\end{equation}

The interpolated data maintains the moments of original data. Among the balance sheet items the highest error is for net interest income, which is on average $\pm 11\%$ different than in the original data. The figure \ref{figure:interpolation_nii} shows the observations behind the error of net interest income. Although the error is the highest among reported, there's no clear pattern across the residuals nor are they asymmetrical, thus indicating that the error is random and well behaved. The errors of Standard deviation are higher than the mean but both are in general overall small. 

\begin{table}
\begin{tabular}{l|c|c}
		Balance sheet item  & Standard deviation & Mean \\
		\hline
		Total Assets & 0.044220 & 0.002405 \\
		Total deposits & 0.059483 & 0.003590 \\
		IB assets & 0.055003 & 0.015665 \\
		IB liabilites & 0.046697 & 0.014772 \\
		%impairment & 0.056730 & 0.035416 \\
		%loans & 0.046495 & 0.002674 \\
		%ltfunding & 0.068009 & 0.016744 \\
		Net interest income & 0.114056 & 0.018165 \\
		%opincome & 0.093375 & 0.013619 \\
\end{tabular}
	\caption{Mean absolute relative error of interpolated data with respect to the original one across}
\label{table:interpolation_error}
\end{table}

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale = 0.7]{img/std_nii.png}
	\caption{Standard deviation of interpolated and original data across. Mean values across time-series of each financial institution.}
	\label{figure:interpolation}
\end{figure}

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale = 0.8]{img/interpolation.png}
	\caption{Asset data interpolation of Commerzbank AG. The orange points are actual data from the balance sheet. The blue line is the interpolated data. The slight discrepency between the maximum or minimum and the data point is due to the moving data to the nearest week end for stock data matching.}
	\label{figure:interpolation_nii}
\end{figure}
\end{document}